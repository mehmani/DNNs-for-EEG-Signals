{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Basic Introduction\n",
    "\n",
    "Four different types of sequence prediction problems:\n",
    "1. Sequence Prediction (Weather forcast, stock market, product recomendation).\n",
    "2. Sequence Classification (DNA sequence classification, Anomaly detection, Sentiment analysis).\n",
    "3. Sequence Generation (Text, ,music, image caption generation).\n",
    "4. Sequence-to-Sequence Prediction (time series prediction, text summarization, program extraction).\n",
    "\n",
    "Poblem of using MLP for LSTM problems:\n",
    "\n",
    "The MLP is better than ARIMA because: it is robust to Noise and missing values and it is nonlinear, can have multivariate inputs, multi-step outputs\n",
    "\n",
    "Issues:\n",
    "\n",
    "- Stateless, and it is unaware of Temporal structure\n",
    "- Messy Scalling, fixed size input and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data prepration:\n",
    "##### Scaling:\n",
    "- Normalize Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "5    60\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [10, 20, 30, 40, 50, 60]\n",
    "series=Series(data)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 10.000000, Max: 60.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alime\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "values = series.values\n",
    "values = values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. ]\n",
      " [ 0.2]\n",
      " [ 0.4]\n",
      " [ 0.6]\n",
      " [ 0.8]\n",
      " [ 1. ]]\n"
     ]
    }
   ],
   "source": [
    "normalized = scaler.transform(values)\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.]\n",
      " [ 20.]\n",
      " [ 30.]\n",
      " [ 40.]\n",
      " [ 50.]\n",
      " [ 60.]]\n"
     ]
    }
   ],
   "source": [
    "# Denormalize\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    5.5\n",
      "2    9.0\n",
      "3    2.6\n",
      "4    8.8\n",
      "5    3.0\n",
      "6    4.1\n",
      "7    7.9\n",
      "8    6.3\n",
      "dtype: float64\n",
      "Mean: 5.355556, StandardDeviation: 2.712568\n",
      "[[-1.60569456]\n",
      " [ 0.05325007]\n",
      " [ 1.34354035]\n",
      " [-1.01584758]\n",
      " [ 1.26980948]\n",
      " [-0.86838584]\n",
      " [-0.46286604]\n",
      " [ 0.93802055]\n",
      " [ 0.34817357]]\n",
      "[[ 1. ]\n",
      " [ 5.5]\n",
      " [ 9. ]\n",
      " [ 2.6]\n",
      " [ 8.8]\n",
      " [ 3. ]\n",
      " [ 4.1]\n",
      " [ 7.9]\n",
      " [ 6.3]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "# define contrived series\n",
    "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape(-1, 1)\n",
    "# train the normalization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "# normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print(standardized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Integer Encoding\n",
    "- One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n"
     ]
    }
   ],
   "source": [
    "values = np.array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 1 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "onehot_encoded = OneHotEncoder(sparse = False)\n",
    "integer_encoded = integer_encoded.reshape(-1,1)\n",
    "print(integer_encoded)\n",
    "onehot_encoded = onehot_encoded.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cold']\n"
     ]
    }
   ],
   "source": [
    "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0,:])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pre-Sequence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [0 1 2 3]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "sequences = [[1,2,3,4],[1,2,3],[1]]\n",
    "padded = pad_sequences(sequences)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pre-Sequence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [1 2 3 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pre-Sequence Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [2 3]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "truncated = pad_sequences (sequences, maxlen=2) \n",
    "print(truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Post-Sequence Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 2]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "truncated = pad_sequences (sequences, maxlen=2, truncating = 'post') \n",
    "print(truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   t  t+1\n",
      "0  0  1.0\n",
      "1  1  2.0\n",
      "2  2  3.0\n",
      "3  3  4.0\n",
      "4  4  5.0\n",
      "5  5  6.0\n",
      "6  6  7.0\n",
      "7  7  8.0\n",
      "8  8  9.0\n",
      "9  9  NaN\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "# define the sequence\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "# shift backward\n",
    "df['t+1'] = df['t'].shift(-1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM in Keras\n",
    "\n",
    "- Input: it  must be three-dimensional, comprised of samples, time steps,and features in that order.\n",
    "    Samples. These are the rows in your data. One sample may be one sequence.\n",
    "    Time steps. These are the past observations for a feature, such as lag variables.\n",
    "    Features. These are columns in your data.\n",
    "- output layer:\n",
    "    Regression: linear activation fucntion\n",
    "    Binary Classification: logistic activation\n",
    "    Multiclass Classification: foftmax activation\n",
    "- Loss funcion:\n",
    "    Regression: Mean Square Error \n",
    "    Binary Classification: Logarithmic Loss (binary_crossantroopy\n",
    "    Multiclass Classification: Multiclass Logarithmic Loss (categorical_crossantropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM State Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, the internal state of all LSTM memory units in the network is reset after each batch, e.g. when the network weights are updated.\n",
    "- To address this issue, Keras provides exibility to decouple the resetting of internal state from updates to network weights by decoupling an LSTM layer as stateful. This can be done by setting the stateful argument on the LSTM layer to True.\n",
    "- A stateful LSTM will not reset the internal state at the end of each batch. Instead, you have fine grained control over when to reset the internal state by calling the reset states() function.\n",
    "- By default, the samples within an epoch are shuffled. This is a good practice when working with Multilayer Perceptron neural networks. If you are trying to preserve state across samples, then the order of samples in the training dataset may be important and must be preserved.\n",
    "\n",
    "Ex. \n",
    "\n",
    " model.fit(X, y, epochs=1, shuffle=False, batch_input_shape=(10, 5, 1))\n",
    " \n",
    " model.reset_states()\n",
    " \n",
    " \n",
    "#### 1D Input Example (input_shape=(10, 1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "data = data.reshape((1, 10, 1))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Input Example (input_shape=(10, 2)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "data = array([\n",
    "[0.1, 1.0],\n",
    "[0.2, 0.9],\n",
    "[0.3, 0.8],\n",
    "[0.4, 0.7],\n",
    "[0.5, 0.6],\n",
    "[0.6, 0.5],\n",
    "[0.7, 0.4],\n",
    "[0.8, 0.3],\n",
    "[0.9, 0.2],\n",
    "[1.0, 0.1]])\n",
    "data = data.reshape(1, 10, 2)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Models:\n",
    "- Sequence Prediction:\n",
    "    One-to-One Model (weather forcasting)\n",
    "    One-to-Many Model (predicting a sequence of word from single image, or forcasting based on one event)\n",
    "    Many-to-One Model (Forcasting based on the sequence, prdicting the classification value)\n",
    "    Many-to-Many Model (text summerization, and classify a sequence of audio into a sequence of words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
